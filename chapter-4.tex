%%
%% VERSION HISTORY
%%    22 May 2006 - John Papandriopoulos - Original version
%%    12 Jul 2007 - John Papandriopoulos - Converted into template
%%

\chapter{Methodology}
	\label{chapter:methodology}%
	%

% preferred location for figures in this chapter
\setfigurepath{figures/chapter-4}

%=========================================================================

%\begin{synopsis}
%	Synopsis.
%\end{synopsis}

%=========================================================================

\section{Introduction}
\subsection{Research question}
Research objective is to explore the feasibility of using NLP and ML to identify at-risk individuals who might develop suicidal ideation in Internet environment. More concretely, the research questions are as follows:
\begin{itemize}
\item How can we improve efficiency of existing work on identifying people with mental health problems who actually develop suicidal ideation on online forum using natural language processing and machine learning?
\item What machine learning techniques are appropriate for such classification task on a large scale?
\end{itemize}
The forum we choose for this experiment is Reddit. In literature, existing work \cite{DeChoudhury2016} already examined suicide support subforum of Reddit and built classifier to pinpoint at-risk users. Although the classifier performed quite well in the research, it performed only on a small sample of entire dataset thus robustness of the classifier in realistic scenario is unknown. We are going to borrow the approach of \cite{DeChoudhury2016} to investigate feasibility of such classifier on a larger population. We will build classifiers with comparable performance and apply it to large dataset collected.
\subsection{Overview of Reddit}
Reddit is a prominent social networking sites with an extremely large user base. Founded in 2005, Reddit has 234 million active users and attracts 542 million visitors per month as of 2017. In term of website ranking based on number of visitor, Reddit ranked 4\textsuperscript{th} in U.S and 9\textsuperscript{th} in the world \cite{Alexa2017}. Reddit aggregates news from many sources including itself, allowing users to discuss by commenting on the original post which is hosted on the sites as a thread. Users can interact with a submission by voting the post/comment up or down to express whether they like or dislike the post/comment. The score of a post (i.e. difference between the number of upvote and downvote for the post) determine the position of the post on the page. The more score a post got, the higher position of the post. This feature allows high scored posts to be highly visible to visitors due to being on top of the page. Figure~\ref{fig:reddit} shows a screenshot of Reddit front page at the time of writing. On front page, posts have gathered high number of upvote in short period of time which can be up to tens of thousands upvotes in several hours.
\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{img/reddit}
\caption{User interface of Reddit front page.} 
\label{fig:reddit}
\end{figure} 
Reddit is organized by areas of interest. Each area of interest or topic has each own space called "subreddit" for posting and discussion, much like a subforum. Convention for typing name of a subreddit is adding "r/" before the name of subreddit to indicate direct link to that subreddit (e.g. \textit{r/movies} refers to Movies subreddit - https://www.reddit.com/r/movies/). Every subreddit is moderated by moderator to ensure posts and comments follow guideline and do not digress from the topic. As moderation entails substantial monitoring, a moderator is either a human or an automated bot. To create a new subreddit, a Reddit user (also known as redditor) must meet specific criteria: his account must be at least 30 days old and his account must accumulate enough post "karma". "Karma" reflects how much a redditor contribute to Reddit community, "karma" can be earned by getting upvotes for external link posted or upvotes for comments. The exact number of karma required for creating new subreddit is unknown to normal users, only admins know. Reddit is very diverse as subreddit topics include various fields ranging from general themes such as science, sport, news, movies, food to specific themes namely r/Moviesinthemaking, r/harrypotter, r/PoliticalHumor.\\
As mentioned in the previous section, Reddit provides a free API\footnote{https://www.reddit.com/dev/api/} for any developers who want to build applications that need to crawl posts and comments on Reddit. There are a variety of scripts that users developed using Reddit API: auto reply bot, auto crawler, auto unit converter, image resizing bot, external link thumbnail displaying bot, message reminder, etc. Most of these bots operate by the principle: getting posts and comments in real time, processing according to programmed procedure, producing output which usually is a comment. For example, a grammar correcting bot crawl all posts/comments in real time, whenever it detects a grammar mistake (say "could of") in a post, it replies to that post explaining and correcting to "could have". Another useful example is unit converter which convert unit from imperial system to metric system since most posts from American use imperial unit while most non-U.S readers are familiar with metric unit.\\
\section{Experimental design}
\subsection{Data collection}
In this experiment, we are using Google BigQuery\footnote{https://cloud.google.com/bigquery/} as an alternative to Reddit API for crawling posts and comments. BigQuery is an IaaS (Infrastructure as a Service) site that interoperate with Google Cloud Storage\footnote{https://cloud.google.com/storage/} to provide interactive analysis of big data warehouses. Its features include managing data, query data, integration to other systems and access control. On BigQuery, data is managed by CRUD operations (Create, Read, Update, Delete) or is imported from Google Storage. The main language used for querying tables is standard SQL or its dialect. Result of a query can be downloaded in CSV (comma-separated values) or JSON (JavaScript Object Notation) format. Owner of the dataset is able to choose options for sharing data with a selected user, with groups or publicly.\\
A dataset of all posts and comments from Reddit is uploaded and update monthly on BigQuery. The tables contain posts and comments of Reddit from 2006 to the latest month can be found at \url{https://bigquery.cloud.google.com/dataset/fh-bigquery:reddit_posts}.\\
We queried the dataset to get posts and comments of 14 MH subreddits and SW subreddit (r/SuicideWatch) from February 11\textsuperscript{th}, 2014 to November 11\textsuperscript{th}, 2014. The list of MH subreddits includes r/mentalhealth, r/bipolarreddit, r/depression, r/ptsd, r/hardshipmates, r/survivorsofabuse, r/StopSelfHarm, r/BPD,  r/psychoticreddit, r/traumatoolbox, r/EatingDisorders, r/rapecounseling. The content in these MH subreddits have been examined and verified to be relevant to mental health discussion theme \cite{Pavalanathan2015}. The data is of JSON format which is identical to built-in data structure \textit{dictionary} of Python. The dataset on BigQuery separate posts and comments into different tables, so we have two JSON files as a result: one consists of posts and the other consists of comments. The total number of posts and comments are 80581 and 409430 respectively. There are 34,549 unique authors who have posted in all these 15 subreddits. Table~\ref{tab:overview} shows breakdown statistics of the dataset.\\
\begin{table}
\noindent\begin{tabularx}{\textwidth}{>{\hsize=0.4\textwidth}XXX}
\toprule
 & MH subreddits & SW subreddit\\ 
\midrule
Number of posts & 60556  & 20025\\
Number of comments & 278100 &  131330\\ 
Average length of posts  & 251  & 250.3\\
Median length of posts & 164  &   165\\
Average length of comments     & 66.7   & 57.2\\
Median length of comments        &  36  &  26\\
\bottomrule
\end{tabularx}
\caption{Overview of the dataset.}
\label{tab:overview}
\end{table}
\begin{table}[h!]
\noindent\begin{tabularx}{\textwidth}{XXXX}
\toprule
\multicolumn{2}{c}{MH subreddits} & \multicolumn{2}{c}{SW subreddit} \\ 
\midrule
Word & Count & Word & Count\\
\midrule
like & 87222 &  like & 25290\\ 
feel  & 75385  & want & 22485\\
know & 64496 &  know &  21755\\
get    & 55209 & life & 21213\\
want  & 52596 & feel & 20429\\
time & 49249 & get & 17066\\
really & 48359 & even & 15100\\
life & 47545 & would & 14854\\
people & 45693 & time & 14826\\
 even & 43755 & people & 14607\\
would & 40328 & one & 14156\\
one & 39295 & really & 14015\\
friends & 33830 & going & 11658\\
think & 32685 & never & 11482\\
go & 32661 & think & 11233\\
depression & 32379 & friends & 11120\\
going & 32089 & go & 11009\\
things & 31335 & much & 10039\\
never & 31227 & years & 9995\\
much & 28790 & help & 9810\\
\bottomrule
\end{tabularx}
\caption{Top 20 common words in each dataset (stopwords excluded).}
\label{tab:common_words}
\end{table}
Table~\ref{tab:common_words} shows common words used among both MHs and SW. Most of those words are common in both dataset and relatively equal in rank such as "like", "people", "think", "know", "one". Those kinds of words are pretty general and do not reveal much about content of the text. However, several words characterize the groups namely "depression", "help", "years". The word "depression" occurs at high frequency in MHs indicate discussion among community while "help", "years" may infer calls for help of at-risk individuals or struggle over a long period.
\subsection{Constructing user classes}
The time span of nine months in our data is split into two periods: the first six months (February 11\textsuperscript{th}, 2014 - August 11\textsuperscript{th}, 2014) and the last three months (August 12\textsuperscript{th}, 2014 - November 11\textsuperscript{th}, 2014). The 'control' group in this experiment is the group of users who do not have suicidal thoughts even though they may encounter problems with mental health. On the other hand, at-risk individuals are defined as people who are challenged by mental disorders and later develop suicidal ideation. In the context of online forum, we can only observe posting activity so we identify users who only posted on MH subreddits during the first six months but never posted on SW subreddit during the last three months as 'control' group (hereafter referred to as MH). Similarly, users who only posted on MH subreddits during the first six months and posted on SW during the last three months are defined as at-risk individual (hereafter referred to as MH$\rightarrow$SW). By "posted" we mean submit a post, that translates to only users that start a discussion are included. This criterion excludes users who only gave commentary and were not subject of the discussion.\\
The procedure returned 465 users of MH$\rightarrow$SW an 24,761 users of MH. To create two balanced classes, we randomly sampled 465 users from 24,761 users. After that, we extracted posts and comments from these users. We discarded all the posts and comments that do not contain text (indicating external links, images or videos) or the content is deleted. Each entry of post gathered contained the title, text, score, number of comments of that post. We had 1,484 posts and 6,115 comments from 465 MH$\rightarrow$SW user and 584 posts, 1,988 comments from 465 MH users. There are some cases we may miss at-risk individuals: users who posted in MH subreddits before February 11\textsuperscript{th}, 2014 or posted in SW subreddit after November 11\textsuperscript{th}, 2014. We assumed the number of such cases is quite small and did not consider to expand the period. Another point to note is all the posts and comments are from 15 mentioned subreddits, users may have posted somewhere else outside these subforums. 
\subsection{Feature selection}
In this section, we present the process of features selection for prediction framework. Our aim is to build a classifier that performs comparable to the classifier built in \cite{DeChoudhury2016}. We chose some features like existing work but some features get removed because it did not improve performance or we cannot recreate such features due to lack of low-level implementation details. There are four sets of features namely \textit{interpersonal awareness, linguistic structure, interaction, sentiment}. Each set has several different variables related to the corresponding category. All these measures are averaged across all posts and comments of a user.
\begin{itemize}
\item \textit{Interpersonal awareness:} this set includes percentage of first person plural (i, me, my, mine), first person singular (we, us, our, ours), second person pronouns (you, your, yours) and third person pronouns (he, she, it, him, her, his, hers, its, they, them, their, theirs). Past work \cite{DeChoudhury2013} used this measure to quantify self-awareness, collective attention and social interaction of an individual.
\item \textit{Linguistic structure:} this measure comprises percentage of nouns, verbs, adverbs and pronouns in submissions; number of 'difficult' words; automated readability index; Fleisch reading ease. The 'difficult' words here are words that have more than three syllables. Fleisch reading ease is a scale to gauge the difficulty of documents in term of understandability. This Fleisch reading ease score is on scale 0-100. A high score indicates the text is easy to read and vice versa. Automated readability index has similar use like Fleisch reading ease but is computed by different formula and the scaled score is reverse to it: the lower score, the easier to read. The nouns, verbs, adverbs and pronouns are labelled by NLTK POS tagger with "Universal" tagset, the remaining variables are calculated using textstat\footnote{https://pypi.python.org/pypi/textstat/} Python package. These variables quantify overall writing structure of a user, suggesting his cognitive state.
\item \textit{Interaction:} variables in this set is associated with metadata of posts and comments namely length of posts/comments submitted, length of titles of posts authored, score for posts/comments submitted, number of comments to post submitted. These kinds of variables show how active a user is on Reddit and how much support that user received.
\item \textit{Sentiment:} this set utilizes sentiment analysis on each post or comment. Each post was assigned four types of polarity score: pos (positive), neg (negative), neu (neutral) and compound score. The scores are calculated using VADER \cite{Hutto2014} introduced in previous section.
\item \textit{Content:} this set includes 90 tokens (unigrams or bigrams) reported in \cite{DeChoudhury2016} that distinguished between MH$\rightarrow$SW. Among these tokens, 70 tokens associated with increase in the likelihood of posting in SW in the future. Whereas the remaining 20 tokens decrease the likelihood of being in MH$\rightarrow$SW. All reported tokens either have highest or lowest treatment effect. This features have binary values:  if a user used a token, variables corresponding to that token is valued 1 or 0 otherwise.
\item \textit{Combined}: this set is combination of all five sets above.
\end{itemize}
\begin{table}[h!]
\noindent\begin{tabularx}{\textwidth}{XXX|XXX}
\toprule
token & treat effect & \textit{z} & token & treat effect & \textit{z} \\
\midrule
depression & 0.3 &  8.04 & money\_i & 0.52 & 5.89\\ 
useless & 0.51 &  7.05 & out\_as & 0.53 & 5.89\\ 
suicide & 0.32 &  6.66 & this\_happened & 0.51 & 5.89\\ 
anxiety & 0.24 &  6.56 & this\_world & 0.5 & 5.88\\ 
suicidal & 0.34 &  6.56 & over\_i & 0.51 & 5.86\\ 
i\_almost & 0.52 &  6.44 & still\_a & 0.51 & 5.85\\ 
and\_an & 0.51 &  6.4 & off\_a & 0.51 & 5.85\\ 
medicine & 0.52 &  6.38 & loneliness & 0.5 & 5.84\\ 
unless\_i & 0.53 &  6.36 & class\_and & 0.52 & 5.84\\ 
hug & 0.52 &  6.36 & alone\_i & 0.34 & 5.84\\ 
they\_didn & 0.51 &  6.33 & am\_the & 0.54 & 5.82\\ 
take\_me & 0.52 &  6.32 & care\_i & 0.52 & 5.79\\ 
and\_give & 0.51 &  6.23 & giving\_me & 0.51 & 5.79\\
shirt & 0.53 &  6.22 & they\_get & 0.51 & 5.79\\ 
happy\_i & 0.52 &  6.21 & capable & 0.49 & 5.79\\ 
i\_talk & 0.51 &  6.2 & keep\_in & 0.52 & 5.77\\ 
locked & 0.51 &  6.17 & the\_amount & 0.52 & 5.76\\ 
can\_t & 0.22 &  6.14 & hate\_it & 0.48 & 5.76\\ 
people\_on & 0.5 &  6.12 & socially & 0.51 & 5.75\\ 
do\_for & 0.52 &  6.11 & increase & 0.51 & 5.75\\ 
problems\_i & 0.51 &  6.08 & t\_keep & 0.52 & 5.75\\ 
anyone\_i & 0.51 &  6.07 & just\_in & 0.51 & 5.73\\
thoughts\_and & 0.53 &  6.07 & picked\_up & 0.5 & 5.73\\ 
ve\_started & 0.52 &  6.04 & t\_help & 0.28 & 5.71\\ 
stuck\_in & 0.5 &  6 & no\_real & 0.5 & 5.71\\ 
no\_friends & 0.51 &  6& alone & 0.19 & 5.71\\ 
but\_only & 0.51 &  5.98 & existing & 0.49 & 5.71\\ 
have\_nothing & 0.51 &5.98  & an\_idiot & 0.51 & 5.71\\ 
require & 0.52 &  5.97 & just\_trying & 0.52 & 5.7\\ 
would\_get & 0.5 &  5.96  & t\_deserve & 0.51 & 5.7\\ 
but\_can & 0.52 & 5.95  & depressive & 0.52 & 5.69\\ 
been\_there & 0.51 & 5.95  & can\_give & 0.51 & 5.69\\ 
who\_don & 0.51 & 5.92  & friends & 0.17 & 5.69\\ 
world\_of & 0.52 & 5.92  & end\_i & 0.51 & 5.69\\ 
kills & 0.53 &  5.9 & existence & 0.5 & 5.68\\ 
\bottomrule
\end{tabularx}
\caption{(Statistically significant) treatment tokens obtained via propensity score matching that contribute to \textit{increased} change in likelihood of posting in SW \cite{DeChoudhury2016}.}
\label{tab:postive_token}
\end{table}
\begin{table}[h!]
\noindent\begin{tabularx}{\textwidth}{XXX|XXX}
\toprule
token & treat effect & \textit{z} & token & treat effect & \textit{z} \\
\midrule
captain & -0.6 & -4 & straight\_up & -0.56 & -3.82\\ 
difference & -0.59 &  -4.47& preferred& -0.56 & -3.71\\ 
the\_trip & -0.57& -3.76 & awesome\_i & -0.56 & -3.68\\ 
intimate &-0.57 & -3.73 & s\_at & -0.55 & -4.83\\ 
to\_in &-0.56 &  -4.92 & stated & -0.55 & -4.8\\ 
too\_hard & -0.56 &  -4.4 & slight &-0.55 & -4.61\\ 
suspect &-0.56 &  -4.4 & and\_enjoy &-0.55& -4.44\\ 
always\_a & -0.56 &  -4.15 & gotten\_to & -0.55& -4.35\\ 
be\_working & -0.56 &  -4.12 & it\_work & -0.55 & -4.22\\ 
keep\_your & -0.56 &  -3.82 & came\_from & -0.55 & -4.21\\ 
\bottomrule
\end{tabularx}
\caption{(Statistically significant) treatment tokens obtained via propensity score matching that contribute to \textit{decreased} change in likelihood of posting in SW \cite{DeChoudhury2016}.}
\label{tab:negative_token}
\end{table}
Table~\ref{tab:postive_token} and Table~\ref{tab:negative_token} derived from \cite{DeChoudhury2016} show 90 tokens mentioned above. The number of token users, population coverage and $\chi^2$ statistics have been omitted. All these tokens are statistically significant as \textit{p}-value \textless 0.001, ordered in descending order of \textit{z}-score (positive treatment effect tokens) or treatment effect (negative treatment effect tokens). This statistic is acquired by using stratified propensity score matching analysis on tokens used by more than 10 users of MHs group which are more than 11,000 tokens.\\
As can be seen in the tables, the token significantly increases the likelihood of posting suicidal ideation in the future by large percentage 17-54\%. Some tokens did not reveal informational content (e.g. "can't", "friends") and have lower treatment effect, below 20\%. In contrast, many tokens gave cues about users' stories and their mental state (e.g. "suicidal", "useless", "depressive", "medicine", "no friends", "locked"). In general, extensive use of such tokens indicate underlying psychological distress, pessimistic perspective, possible severe illness that need medication of users. \\
On the other hand, some tokens decrease the likelihood of posting in SW subreddit. Tokens such as "awesome i", "and enjoy", "the trip", "it work" show significant more positive attitude than tokens mentioned above. Use of tokens like that signals sign of relief, recovery from hardship, enjoyment in life from users. Treatment effect of these tokens is very noteworthy, around -55\% to -60\%.\\
According to \cite{DeChoudhury2017}, stratified propensity score matching may encounter problems of imbalance in strata. That means the use of a token may have different effects on different users. Some users saw significant change in probability of joining  MH$\rightarrow$SW while some do not. There are tokens that both increase and decrease the likelihood of posting in  SW so we do not incorporate such token into our features.\\
\subsection{Experimental settings}
We devise two settings for this experiment:\\
(1) \textbf{Theoretical setting:} in this setting, we runs classifier in two balanced classes with equal sample size. That mean there are 465 MH users and 465 MH$\rightarrow$SW users in the dataset. The purpose of this setting is to compare with classification framework in \cite{DeChoudhury2016}. If the performance is comparable, we can apply the same classifier in the other setting.\\
(2) \textbf{Realistic setting:} in reality, the number of people challenged by mental health problems but do not consider suicide is different from people with similar problem and eventually develop suicidal ideation. As we can see in our data, MH users outnumbers MH$\rightarrow$SW users by a tremendous amount. The total number of MH$\rightarrow$SW users is only 1.84\% of total users in final dataset. The final dataset for this setting contained 465 MH$\rightarrow$SW users and 24,761 MH users. We are going to classify MH$\rightarrow$SW users from MH users by using the same classification framework in theoretical setting.\\
The ML algorithms used in this experiments are Logistic regression, Na\"ive Bayes and Support Vector Machine. We performed 10-fold cross validation on the final dataset and run the model 10 times to mitigate randomness of cross validation. The evaluation metrics will be the standard metrics in most of supervised ML tasks: \textit{precision, recall} and \textit{F-1 measures}. Table~\ref{tab:confusion_matrix} shows confusion matrix for this task.\\
\begin{table}
\begin{tabular}{l|l|c|c|c}
\multicolumn{2}{c}{}&\multicolumn{2}{c}{True condition}&\\
\cline{3-4}
\multicolumn{2}{c|}{} & MH$\rightarrow$SW &  MH \\
\cline{2-4}
\multirow{2}{*}{Prediction outcome} & MH$\rightarrow$SW & True Positive (TP) &  False Positive (FP) \\
\cline{2-4}
& MH & False Negative (FN) & True Negative (TN) \\
\cline{2-4}
\end{tabular}
\caption{Confusion matrix for the classification task.}
\label{tab:confusion_matrix}
\end{table}
\textit{Precision} measures the rate of our correct prediction of MH$\rightarrow$SW users over the total users we have predicted to be MH$\rightarrow$SW.
\begin{equation*}
Precision = \frac{TP}{TP + FP}
\end{equation*}
\textit{Recall} measures the rate of correct prediction of MH$\rightarrow$SW over the total number of MH$\rightarrow$SW users.
\begin{equation*}
Recall = \frac{TP}{TP + FN}
\end{equation*}
 F-1 measure is the harmonic mean of precision and recall.
\begin{equation*}
F_1 = 2 * \frac{Precision * Recall}{Precision + Recall}
\end{equation*}
\section{Result}
\subsection{Differences in linguistic, interpersonal, interaction and sentiment features}
\begin{table}[h!]
\noindent\begin{tabularx}{\textwidth}{>{\hsize=0.4\textwidth}XXXXX}
\toprule
& MH  & MH$\rightarrow$SW & \textit{z} & \textit{p}\\
\midrule
\rowcolor{gray}
\multicolumn{5}{c}{Interaction} \\ 
Post length  & 267.6  & 265.9  & 0.09 & -\\
Title length  & 7.88  &  8.31  &  -1.10 & -\\
Post score  & 6.0 & 5.7   & 0.24 &  -\\
\# Comments received  & 3.99 & 5.49 & -2.15 & *\\
\# Comments submitted & 3.96 & 13.1 & -6.34 & *\\
Comment length & 46.5 & 63.4 & -2.83 &  * \\
Comment score & 1.07 & 1.51 & -3.86 & *\\
\rowcolor{gray}
\multicolumn{5}{c}{Linguistic structure} \\ 
\# Difficult words & 55.0 & 52.6 & 0.69 & -\\
Fleisch reading ease & 70.7 & 75.5 & -2.71 & *\\
Automated reading index & 7.04 & 7.14 & -0.2  & -\\
\% Pronouns  & 0.07 & 0.08 & -2.05  & *\\
\% Nouns & 0.21& 0.19 & 2.96  &  *\\
\% Verbs & 0.22 & 0.25 & -4.72  &  *\\
\% Adverbs & 0.08 & 0.08 & -0.91  &  -\\
\rowcolor{gray}
\multicolumn{5}{c}{Interpersonal awareness} \\ 
\% 1st person singular & 0.09 & 0.10 & -5.88 & *\\
\% 1st person plural & 0.0026 & 0.0024 & 0.65 & -\\
\% 2nd person pronouns & 0.005 & 0.004 & 1.23 &-\\
\% 3rd person pronouns & 0.032 & 0.031 & 0.41 & -\\
\rowcolor{gray}
\multicolumn{5}{c}{Sentiment analysis} \\
Negative score & 0.13 & 0.15 & -5.1 & *\\
Neutral score  & 0.68 & 0.69  & -0.65 & -\\
Positive score & 0.115 & 0.114 & -0.31 &-\\
Compound score & -0.19 & -0.36 & 3.98 & *\\
\bottomrule
\end{tabularx}
\caption{Theoretical setting: summary of feature sets for MH users class and  MH$\rightarrow$SW users class.}
\label{tab:z_test}
\end{table}
Table~\ref{tab:z_test} show means of measures of two user classes. Half of these measures characterize differences between MH and MH$\rightarrow$SW. We performed z-test on two samples and show statistical significance at \textit{p} = 0.05 level. An asterisk "*" denotes the difference between two populations is statistically significant and a dash "-" denotes otherwise. Each of the categories namely structure of language, social awareness, sentiment analysis and forum interaction have variables that are statistically significant. Thus, we can observe some differences between two classes and they may suggest some psychological phenomena.\\
In the set of features related to forum interaction, we see differences in term of comments between MH users and MH$\rightarrow$SW users. MH$\rightarrow$SW users submitted far more comments than MH users (z = -6.34). MH$\rightarrow$SW users also received more comments from other in their posts (z = -2.15). Note that all posts and comments are in MH and SW subreddit so variables that quantify commentary of  MH$\rightarrow$SW users may be indicative of active engagement in mental health communities of  MH$\rightarrow$SW users. Both length of comments authored by MH$\rightarrow$SW users and score of those comments are higher than that of MH users. Such differences may imply the concerns of MH$\rightarrow$SW in mental health area. Prior work \cite{DeChoudhury2016} show the opposite that MH$\rightarrow$SW display symptoms of social isolation. This may be true in general context where dataset in previous work also included posts from different subreddits. However, this observation suggests that MH$\rightarrow$SW users are usually active in mental health related communities, not other areas of interest.\\
Linguistic structure features show differences in readability; use of pronouns, nouns, and verbs. Automated reading index could not capture discrepancy of understandability of users from two classes while Fleisch reading ease reflected lower coherence in text from MH$\rightarrow$SW users (z = -2.71). Lower use of nouns (z = 2.96) reveals little concerns for topics \cite{Coppersmith2014}and higher use of verbs (z = -4.72) show focus on actions which may have connection to self-disclosure on social media \cite{Houghton2012}. Surprisingly, the number of 'difficult' words (words have more than 3 syllables) shows no difference despite poorer linguistic structure of MH$\rightarrow$SW users.\\
First person singular pronouns are used more by MH$\rightarrow$SW users (z = -5.88). This reflects higher self-focus and have tendency to express personal thoughts more than MH users. This observation is consistent with suggestion that MH$\rightarrow$SW users may involve in self-disclosure posting activity more than normal.\\
Sentiment analysis show more negative attitude and pessimistic outlook of MH$\rightarrow$SW users. Both negative polarity score and compound score of MH$\rightarrow$SW users' posts and comments are lower than MH users' submissions (z = -5.1 and z = 3.98 respectively). This may link to emotional distress or hardship confrontation.\\
\begin{table}
\noindent\begin{tabularx}{\textwidth}{>{\hsize=0.4\textwidth}XXXXX}
\toprule
& MH  & MH$\rightarrow$SW & \textit{z} & \textit{p}\\
\midrule
\rowcolor{gray}
\multicolumn{5}{c}{Interaction} \\ 
Post length  & 282.5  & 265.9  & 1.11 & -\\
Title length  & 8.18  &  8.31  &  -0.46 & -\\
Post score  & 6.2 & 5.7   & 0.4 &  -\\
\# Comments received  & 4.18 & 5.49 & -3.4 & *\\
\# Comments submitted & 4.3 & 13.1 & -11.5 & *\\
Comment length & 41.9 & 63.4 & -6.9 &  * \\
Comment score & 1.07 & 1.51 & -5.19 & *\\
\rowcolor{gray}
\multicolumn{5}{c}{Linguistic structure} \\ 
\# Difficult words & 57.1 & 52.6 & 1.67 & -\\
Fleisch reading ease & 69.7 & 75.5 & -2.76 & *\\
Automated reading index & 7.55 & 7.14 & 0.66  & -\\
\% Pronouns  & 0.07 & 0.08 & -2.17  & *\\
\% Nouns & 0.21& 0.19 & 2.74  &  *\\
\% Verbs & 0.23 & 0.25 & -5.26  &  *\\
\% Adverbs & 0.084 & 0.082 & -1.4  &  -\\
\rowcolor{gray}
\multicolumn{5}{c}{Interpersonal awareness} \\ 
\% 1st person singular & 0.09 & 0.10 & -6.22 & *\\
\% 1st person plural & 0.0025 & 0.0024 & 0.38 & -\\
\% 2nd person pronouns & 0.005 & 0.004 & 1.39 &-\\
\% 3rd person pronouns & 0.031 & 0.031 & -0.37 & -\\
\rowcolor{gray}
\multicolumn{5}{c}{Sentiment analysis} \\
Negative score & 0.13 & 0.15 & -7.8 & *\\
Neutral score  & 0.68 & 0.69  & -1.24 & -\\
Positive score & 0.114 & 0.115 & -1.29 &-\\
Compound score & -0.18 & -0.36 & 5.2 & *\\
\bottomrule
\end{tabularx}
\caption{Realistic setting : summary of feature sets for MH users class and  MH$\rightarrow$SW users class.}
\label{tab:z_realisitc}
\end{table}
Table~\ref{tab:z_realisitc} shows results of z-test between means of variables of the two user classes in realistic setting. The column for MH$\rightarrow$SW users is identical to that of the previous table. There is no change in column of \textit{p} as well, meaning all statisticcally significant variables in theoretical setting still hold their validity in this z-test. This table confirmed representability of MH random sample in this experiment.  
\subsection{Classification results}
\subsubsection*{Results of the classifiers in theoretical setting}
\begin{table}[h!]
\noindent\begin{tabularx}{\textwidth}{XXXX|XXX|XXX}
\toprule
&\multicolumn{3}{c}{Logistic Regression}&\multicolumn{3}{|c|}{Na\"ive Bayes}&\multicolumn{3}{c}{SVM} \\
\midrule
& P  & R & F1 & P  & R & F1 &P  & R & F1 \\
\midrule
IA    & 0.56  &0.65 & 0.60 & 0.54  & 0.82 & 0.65 & 0.54  & 0.69 & 0.60 \\
LS    & 0.53  & 0.70 & 0.60 & 0.51  & 0.92 & 0.66 &0.59   & 0.54 & 0.56 \\
I     & 0.66  & 0.61 & 0.63 & 0.57 & 0.78 & 0.63&  0.52 & \textbf{0.94} & 0.67 \\
S    & 0.55  & 0.61 & 0.58 & 0.58 & 0.82 & 0.68 &0.65  & 0.60 & 0.62 \\
C    &   0.71 & 0.60 & 0.65 & \textbf{0.77}  & 0.32 & 0.45 & 0.70  & 0.66 & 0.67 \\
Com & 0.76 & 0.66 & \textbf{0.70} & 0.70  & 0.46 & 0.56 & 0.56  & 0.79 & 0.65 \\
\bottomrule
\end{tabularx}
\caption{Theoretical setting: classification results of SVM, Na\"ive Bayes, Logistic regression on six sets of features.}
\label{tab:theory_result}
\end{table}
We report classification results of balanced classes setting in Table~\ref{tab:theory_result}. There are abbreviations in the table: IA = Interpersonal Awareness, LS = Linguistic Structure, I = Interaction, S = Sentiment analysis, C = Content features, Com = Combined features. All the results reported are averaged after performing 10-fold cross validation. Overall, the classifier logistic regression on combined set of features give the best performance (F1 = 0.70). In term of precision, Na\"ive Bayes give the highest precision on content features (P = 0.77) followed by logistic regression performed on combined features (P = 0.76). The highest recall among all classifier is achieved by SVM on interaction features (R = 0.94), slightly higher than Na\"ive Bayes with linguistic features. The Na\"ive Bayes classifier displayed the nature of tradeoff in machine learning clearly: when it classifies using the first four sets of features, average recall obtained is very high (0.78-  0.92) while average precision remains relatively low (0.51 - 0.58); the other two sets produced relatively high precision (0.77, 0.70) but recall results are below average (0.32, 0.46). The performance of logistic regression is quite consistent and comparable to one in \cite{DeChoudhury2016}. Our best results for logistic regression with combined dataset in one run are P = 0.87, R = 0.78 and F1 = 0.82. We are going to proceed to use these classifiers in the realistic setting. 
\subsubsection*{Results of the classifiers in realistic setting}
\begin{table}[h!]
\small
\noindent\begin{tabularx}{\textwidth}{X|X|X}
\toprule
Predicted / Actual &  MH$\rightarrow$SW & MH\\ 
\midrule
 MH$\rightarrow$SW & 0 & 0  \\
MH & 47 &  2476 \\ 
\midrule
Accuracy & \multicolumn{2}{c}{98.1\%}\\
Precision &\multicolumn{2}{c}{0}  \\
Recall     &\multicolumn{2}{c}{0} \\
F-1        &    \multicolumn{2}{c}{0}  \\
\bottomrule
\end{tabularx}
\caption{Realistic setting: SVM classifier performance}
\label{tab:svm_performance}
\end{table}
\begin{table}[h!]
\small
\noindent\begin{tabularx}{\textwidth}{X|X|X}
\toprule
Predicted / Actual &  MH$\rightarrow$SW & MH\\ 
\midrule
 MH$\rightarrow$SW & 1  & 4  \\
MH &  46 & 2473\\ 
\midrule
Accuracy & \multicolumn{2}{c}{98\%}\\
Precision &\multicolumn{2}{c}{0.2}  \\
Recall     &\multicolumn{2}{c}{0.02} \\
F-1        &    \multicolumn{2}{c}{0.03}  \\
\bottomrule
\end{tabularx}
\caption{Realistic setting: Logistic regression classifier performance}
\label{tab:logistic_performance}
\end{table}
\begin{table}[h!]
\small
\noindent\begin{tabularx}{\textwidth}{X|X|X}
\toprule
Predicted / Actual &  MH$\rightarrow$SW & MH \\ 
\midrule
 MH$\rightarrow$SW & 29 & 564\\
MH & 18 & 1912\\ 
\midrule
Accuracy & \multicolumn{2}{c}{76.9\%}\\
Precision &\multicolumn{2}{c}{0.04}  \\
Recall     &\multicolumn{2}{c}{0.61} \\
F-1        &    \multicolumn{2}{c}{0.07}  \\
\bottomrule
\end{tabularx}
\caption{Realistic setting: Na\"ive Bayes classifier performance}
\label{tab:nb_performance}
\end{table}
Table~\ref{tab:svm_performance}, Table~\ref{tab:logistic_performance} and Table~\ref{tab:nb_performance} show the performance of the three classifiers in three single runs. Our objective is to correctly identify MH$\rightarrow$SW users in the population so we chose the runs that have the highest numbers of true positive outcomes. Overall, the prediction outcomes are skewed heavily toward the MH class. SVM overlooked all MH$\rightarrow$SW instances thus failed to classify any MH$\rightarrow$SW users. Since the MH class overwhelms MH$\rightarrow$SW class by enormous amount (47 MH$\rightarrow$SW  vs 2476 MH), the classifier still achieved high accuracy (98.1\%). The logistic regression classifier returned 5 MH$\rightarrow$SW instances but only 1 was correct, attained precision = 0.2, recall = 0.02, F1 = 0.03 and accuracy = 98\%. Among three classifiers, Na\"ive Bayes gave the highest number of true positive instances (TP = 29) thus achieved impressive recall = 0.61. However, the number of false positive cases is far too high (FP = 564) compared to the other classifiers. As a result, precision is dragged down to 0.04, giving F1 = 0.07 which is higher than logistic regression but by no mean can be considered reasonable in ML context.\\
Both results of SVM and logistic regression classifiers presented above are representative of overall performance on all sets of features. That means no matter what set of features is chosen for the classification task, the result is pretty much the same for SVM and logistic regression classifiers. Nevertheless, this is not the case for Na\"ive Bayes. It gave similar results for the first four sets (linguistic structure, forum interaction, sentiment scores, interpersonal awareness) with  TP = 0 and TN = 2476. The 'content' set and the combined set returned more than 17 True Positive cases each run. Features in combined set are largely from the 'content' set (90/112 features). This contribution may be attributed to similarity of performance of the classifiers on the two sets of features.\\ 
\section{Discussion}
Recently, prior works \cite{Coppersmith2016, DeChoudhury2016} made attempts to predict which online social media users have high risk to have suicidal thoughts or suicide attempts. We borrowed the approach of using Reddit data to identify such users. As compared to classifier from \cite{DeChoudhury2016} in the same scheme, our logistic regression classifiers gave comparable performance. Note that our dataset is smaller as we only focus on posts and comments in 15 subreddits while their dataset contained all posting history of a user regardless of topics discussed. We also have fewer features for the classification task. The methods of feature selection and dataset filtering reduce computation required for the task. This reduction is meaningful in practical context where computing resources are valuable as volume of data generated by Internet users is gigantic.\\
In the feature selection step, polarity scores based on sentiment analysis of each posts and comments were incorporated into the model. Hypothesis testing show statistical significance of mean differences of negative scores as compound scores between the MH group and MH$\rightarrow$SW group. These scores reflect negative attitude, decreased mental well-being of individuals who belong to at-risk group. We also saw difference between number of comments authored, average length of comment and score for those comments are higher for MH$\rightarrow$SW users. This difference indicates more active engagement in mental health related communities of at-risk individuals which is counter-intuitive as existing literature \cite{Coppersmith2014} suggested detachment from social interaction of at-risk individuals. Perhaps topics of concerns of those people are narrowed down when they face emotional distress, anxiety or other psychological disorders.\\
We explored the feasibility of applying those ML classifiers in realistic context where true at-risk individuals only occupy a small proportion in entire population (1.8\% in the experiment). Performance of the classifiers dropped completely in this setting as both SVM and logistic regression failed to predict true positive instances which are 0 in most runs. Although Na\"ive Bayes returned a reasonable number of true positive cases, false positive became tradeoff with over 550 false positives in the result. Overfitting rendered SVM and logistic regression less pragmatic in tasks that have huge imbalance between classes in term of raw count. If a classifier with similar performance of  Na\"ive Bayes is adopted for such task, additional screening is certainly needed to reduce problems caused by high number of false positive instances.\\
The experiment addressed the research questions. Firstly, we built three classifiers and sets of features that contained fewer features than that of the existing work. De Choudhury and her colleagues \cite{DeChoudhury2016} incorporated all unigrams, bigrams of the tens of thousands of posts/comments and their relative frequencies as 'content' features. The dataset used in our experiment is also smaller in size due to posts and comments limited in particular subreddits. Nevertheless, the performance did not decrease, suggesting high efficiency in step of feature selection. Secondly, the experiment setting without class balance in dataset examined robustness of said classifiers. It shows that generalizability of this approach is quite poor if problem of overfitting is not addressed, possibly by adding more features, applying more regularization techniques. Na\"ive Bayes classifier did not suffer from overfitting but its precision is not desirable in practice.\\
There are several limitations and caveats in this study. The number of subreddits examined is quite small considering Reddit has many other prominent mental health communities such as eating disorder, addiction, schizophrenia, etc. These kinds of mental illness are possibly responsible for many cases of suicide in general. Since Reddit does not restrict user to own only one account, our dataset may be contaminated by people who posted under multiple accounts or throwaway account. The experiment only utilized three mainstream classifiers while ML offers many more algorithms or approaches such as Decision tree,  Ensemble meta classifier, Neural networks, etc. Furthermore, only posting activity is covered in this study as predictor variables but mental well-being of one person affected by many other factors like financial stability, relationship, physical illness. Such factors and other elements outside of Reddit cannot be observed with this approach. In some unusual cases, the original poster may not be the one that has suicidal thoughts. Instead, they do ask for advices from community but for their acquaintances, their friends or their loved one. That cases and similar ones may flag false predisposition to suicidal thoughts and need to exclude from analysis.\\
